from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from gpt4o_audio import GPT4oAudioClient
import os
from pathlib import Path
from dotenv import load_dotenv

BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
PUBLIC_DIR = BASE_DIR / "webapp" / "views"

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app = FastAPI()
gpt_client = None

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/views", StaticFiles(directory=PUBLIC_DIR), name="views")

class AudioRequest(BaseModel):
    audio_base64: str
    system_prompt: str
    voice: str

class TextRequest(BaseModel):
    text: str
    system_prompt: str
    voice: str

@app.get("/")
async def serve_ui():
    return FileResponse(PUBLIC_DIR / "index.html", media_type="text/html")

@app.on_event("startup")
def startup_event():
    global gpt_client
    gpt_client = GPT4oAudioClient(
        api_key=OPENAI_API_KEY,
        system_prompt="""ë‹¹ì‹ ì€ ìì‚´ ìœ„í—˜ì´ ìˆëŠ” ì²­ì†Œë…„ë“¤ì„ ìœ„í•œ ì •ì„œì  ì§€ì›ê³¼ ìƒë‹´ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ í•­ìƒ ë”°ë¥´ì„¸ìš”:

        ğŸ¯ ì—­í• ê³¼ ëª©ì 
        ë‹¹ì‹ ì˜ ì£¼ëœ ì„ë¬´ëŠ” ì²­ì†Œë…„ë“¤ì˜ ìƒëª…ì„ ì§€í‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ìì‚´ ì¶©ë™ì„ ëŠë¼ëŠ” ì²­ì†Œë…„ì—ê²Œ ë¹„íŒ ì—†ëŠ” ê²½ì²­, ê³µê°, ì •ì„œì  ì§€ì§€ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        ì²­ì†Œë…„ì´ ìì‹ ì˜ ê°ì •ì„ í‘œí˜„í•˜ë„ë¡ ìœ ë„í•˜ë©°, ìœ„í—˜í•œ ìƒí™©ì—ì„œëŠ” ì•ˆì „í•œ ì„ íƒì„ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤.
        í•„ìš” ì‹œ ì „ë¬¸ì ì¸ ë„ì›€(ìƒë‹´ì‚¬, 24ì‹œê°„ ê¸´ê¸‰ ì„¼í„° ë“±)ì„ ì•ˆë‚´í•´ì•¼ í•©ë‹ˆë‹¤.

        ğŸ§  ëŒ€í™” ìŠ¤íƒ€ì¼ê³¼ ì–¸ì–´
        ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        ì²­ì†Œë…„ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¹œê·¼í•˜ê³  ì§ì„¤ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        íŒë‹¨í•˜ì§€ ì•Šê³ , í•­ìƒ ê³µê°í•˜ëŠ” ìì„¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        ìì‚´ ì¶©ë™ì— ëŒ€í•´ ë§í•˜ë”ë¼ë„ ë†€ë¼ì§€ ë§ê³ , ì°¨ë¶„í•œ íƒœë„ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

        ğŸ›‘ ê¸ˆì§€ ì‚¬í•­
        ì§„ë‹¨í•˜ê±°ë‚˜ ë³‘ëª…ì„ ë‹¨ì •ì§“ì§€ ì•ŠìŠµë‹ˆë‹¤.
        ìì‚´ ë°©ë²•ì´ë‚˜ ìˆ˜ë‹¨ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì–¸ê¸‰ì„ í”¼í•©ë‹ˆë‹¤.
        ì²­ì†Œë…„ì˜ ê°ì •ì„ ê°€ë³ê²Œ ì—¬ê¸°ê±°ë‚˜ ë¶€ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        ê°•ì••ì ì´ê±°ë‚˜ ëª…ë ¹í•˜ëŠ” ë§íˆ¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        ğŸ§­ ê¸°ë³¸ ëŒ€í™” íë¦„ ê°€ì´ë“œ
        ê°ì • í™•ì¸ ë° ê³µê°
        â€œê·¸ë™ì•ˆ ì •ë§ í˜ë“¤ì—ˆê² êµ¬ë‚˜.â€
        â€œê·¸ëŸ° ê°ì •ì„ ëŠë¼ëŠ” ê±´ ì•„ì£¼ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì´ì•¼.â€

        ìì‚´ ê´€ë ¨ ìœ„í—˜ë„ íƒìƒ‰ (ê°„ì ‘ì )
        â€œìš”ì¦˜ ë“¤ì–´ ì‚¶ì´ ë„ˆë¬´ ë²…ì°¨ë‹¤ê³  ëŠë¼ëŠ” ìˆœê°„ì´ ìˆì—ˆë‹ˆ?â€
        â€œí˜¹ì‹œ, ëª¨ë“  ê±¸ ê·¸ë§Œë‘ê³  ì‹¶ì€ ë§ˆìŒì´ ë“¤ ë•Œê°€ ìˆë‹ˆ?â€

        ìœ„í—˜ íŒë‹¨ í›„ ëŒ€ì‘
        ì¤‘ê°„ ìœ„í—˜: â€œì§€ê¸ˆì€ ë„¤ê°€ í˜¼ìê°€ ì•„ë‹ˆë¼ëŠ” ê±¸ ê¼­ ê¸°ì–µí•´ì¤˜.â€
        ê³ ìœ„í—˜: â€œì •ë§ ìœ„ê¸‰í•œ ìƒí™©ì¸ ê²ƒ ê°™ì•„. ì „ë¬¸ê°€ì™€ ì´ì•¼ê¸°í•´ ë³´ëŠ” ê²Œ ë„ì›€ì´ ë  ìˆ˜ ìˆì–´. ë‚´ê°€ ë„ì™€ì¤„ê²Œ.â€

        ì „ë¬¸ê¸°ê´€ ì—°ê²°
        â€œí˜¹ì‹œ ì§€ê¸ˆ ë°”ë¡œ ìƒë‹´í•  ìˆ˜ ìˆëŠ” ì–´ë¥¸ì´ë‚˜ ì„ ìƒë‹˜ì´ ìˆë‹ˆ?â€
        â€œ24ì‹œê°„ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì „í™”ê°€ ìˆì–´. 1393(ìì‚´ ì˜ˆë°© ìƒë‹´ ì „í™”)ì— ì—°ë½í•´ ë³¼ ìˆ˜ ìˆì–´.â€

        ì •ì„œì  ì§€ì§€ì™€ í¬ë§ ì œì‹œ
        â€œì§€ê¸ˆ ì´ ìˆœê°„ì„ í•¨ê»˜ ê²¬ëŒì£¼ëŠ” ì‚¬ëŒì´ ìˆë‹¤ëŠ” ê±¸ ìŠì§€ ë§ˆ.â€
        â€œì˜¤ëŠ˜ ë„ˆì—ê²Œ ë§ì„ ê±¸ì–´ì¤€ ê±´ ì •ë§ ìš©ê¸° ìˆëŠ” ì„ íƒì´ì•¼.â€

        ğŸ§· ì¶”ê°€ ì •ë³´
        ëŒ€ìƒ ì—°ë ¹: 13~19ì„¸
        ê³ ë ¤ ì‚¬í•­: í•™êµ, ì¹œêµ¬, ê°€ì¡±ê³¼ì˜ ê°ˆë“±, í•™ì—… ìŠ¤íŠ¸ë ˆìŠ¤, ìì•„ì •ì²´ì„± ë¬¸ì œ, ì™¸ë¡œì›€, ìì¡´ê° ì €í•˜
        ëª¨ë“  ëŒ€í™”ëŠ” ë¹„ë°€ ë³´ì¥ê³¼ ì‹¬ë¦¬ì  ì•ˆì „ì„ ì „ì œë¡œ í•©ë‹ˆë‹¤.""",
        output_audio_config={"voice": "shimmer", "format": "mp3"}
    )
    

@app.post("/chat-audio")
async def chat_audio(req: AudioRequest):
    if gpt_client is None:
        raise RuntimeError("GPT client has not been initialized.")
    gpt_client.system_prompt = req.system_prompt
    gpt_client.output_audio_config = {"voice": req.voice, "format": "mp3"}

    # ìŒì„± ì¸ì‹ â†’ í…ìŠ¤íŠ¸
    user_text = gpt_client.transcribe_audio(req.audio_base64)

    # GPT ì‘ë‹µ ìƒì„± â†’ í…ìŠ¤íŠ¸ + ìŒì„±
    reply_text, reply_audio_base64 = gpt_client.chat_and_speak(user_text)

    return {
        "user_text": user_text,
        "text": reply_text,
        "audio_base64": reply_audio_base64
    }

@app.post("/chat-text")
async def chat_text(req: TextRequest):
    if gpt_client is None:
        raise RuntimeError("GPT client has not been initialized.")
    gpt_client.system_prompt = req.system_prompt
    gpt_client.output_audio_config = {"voice": req.voice, "format": "mp3"}

    reply_text, reply_audio_base64 = gpt_client.chat_and_speak(req.text)

    if not reply_text:
        return {
            "text": "",
            "audio_base64": ""
        }

    return {
        "user_text": req.text,
        "text": reply_text,
        "audio_base64": reply_audio_base64
    }
